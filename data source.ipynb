{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76205589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2021\n",
      "Processing Year: 2022\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Set the working directory where you want to save the data\n",
    "os.chdir(r\"C:\\Users\\ryanb\\OneDrive\\Desktop\\School\\Projects\\fantasy point predictor\\data\")\n",
    "\n",
    "# Define constants\n",
    "POSITIONS = ['qb', 'rb', 'wr', 'te', 'k', 'dst']\n",
    "MIN_YEAR = 2021\n",
    "CURRENT_YEAR = datetime.now().year\n",
    "MIN_WEEK = 1\n",
    "MAX_WEEK = 18\n",
    "\n",
    "# Dictionary to map full team names (used in projections for DST) to their abbreviations\n",
    "TEAM_ABBREVIATIONS = {\n",
    "    \"Arizona Cardinals\": \"ARI\", \"Atlanta Falcons\": \"ATL\", \"Baltimore Ravens\": \"BAL\",\n",
    "    \"Buffalo Bills\": \"BUF\", \"Carolina Panthers\": \"CAR\", \"Chicago Bears\": \"CHI\",\n",
    "    \"Cincinnati Bengals\": \"CIN\", \"Cleveland Browns\": \"CLE\", \"Dallas Cowboys\": \"DAL\",\n",
    "    \"Denver Broncos\": \"DEN\", \"Detroit Lions\": \"DET\", \"Green Bay Packers\": \"GB\",\n",
    "    \"Houston Texans\": \"HOU\", \"Indianapolis Colts\": \"IND\", \"Jacksonville Jaguars\": \"JAX\",\n",
    "    \"Kansas City Chiefs\": \"KC\", \"Las Vegas Raiders\": \"LV\", \"Los Angeles Chargers\": \"LAC\",\n",
    "    \"Los Angeles Rams\": \"LAR\", \"Miami Dolphins\": \"MIA\", \"Minnesota Vikings\": \"MIN\",\n",
    "    \"New England Patriots\": \"NE\", \"New Orleans Saints\": \"NO\", \"New York Giants\": \"NYG\",\n",
    "    \"New York Jets\": \"NYJ\", \"Philadelphia Eagles\": \"PHI\", \"Pittsburgh Steelers\": \"PIT\",\n",
    "    \"San Francisco 49ers\": \"SF\", \"Seattle Seahawks\": \"SEA\", \"Tampa Bay Buccaneers\": \"TB\",\n",
    "    \"Tennessee Titans\": \"TEN\", \"Washington Commanders\": \"WAS\",\n",
    "}\n",
    "\n",
    "# Dictionary to hold the final, merged data for each position\n",
    "merged_position_dfs = {pos: pd.DataFrame() for pos in POSITIONS}\n",
    "\n",
    "# Loop through years and weeks\n",
    "for year in range(MIN_YEAR, CURRENT_YEAR):\n",
    "    print(f\"Processing Year: {year}\")\n",
    "    for week in range(MIN_WEEK, MAX_WEEK + 1):\n",
    "        projections_week = {}\n",
    "        actuals_week = {}\n",
    "\n",
    "        # Loop through each data type and position\n",
    "        for data_type in ['projections', 'stats']:\n",
    "            for position in POSITIONS:\n",
    "                # Construct URL based on data type and position\n",
    "                if data_type == 'projections':\n",
    "                    scoring = \"&scoring=PPR\" if position in ['rb', 'wr', 'te'] else \"\"\n",
    "                    url = f\"https://www.fantasypros.com/nfl/projections/{position}.php?week={week}&year={year}{scoring}\"\n",
    "                else:  # 'stats'\n",
    "                    url = f\"https://www.fantasypros.com/nfl/stats/{position}.php?year={year}&week={week}&scoring=PPR&range=week\"\n",
    "\n",
    "                # Fetch and Process Data\n",
    "                try:\n",
    "                    response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "                    if not response.ok:\n",
    "                        print(f\"Skipping {data_type} for {position.upper()} Week {week}, {year} (URL not found: {response.status_code})\")\n",
    "                        continue\n",
    "                    tables = pd.read_html(StringIO(response.text))\n",
    "                    if not tables:\n",
    "                        print(f\"No {data_type} table found for {position.upper()} Week {week}, {year}\")\n",
    "                        continue\n",
    "                    df = tables[0].copy()\n",
    "\n",
    "                    # Clean DataFrame based on data type\n",
    "                    if isinstance(df.columns, pd.MultiIndex):\n",
    "                        df.columns = [f\"{col[0]}_{col[1]}\" for col in df.columns]\n",
    "                        df.rename(columns={'MISC_FPTS': 'FPTS'}, inplace=True)\n",
    "                    \n",
    "                    player_col_index = 0 if data_type == 'projections' else 1\n",
    "                    if len(df.columns) > player_col_index:\n",
    "                        df.rename(columns={df.columns[player_col_index]: 'Player'}, inplace=True)\n",
    "                    else:\n",
    "                        print(f\"Could not find player column in {data_type} for {position.upper()} Week {week}, {year}\")\n",
    "                        continue\n",
    "\n",
    "                    if data_type == 'projections':\n",
    "                        if position == 'dst':\n",
    "                            df['Team'] = df['Player'].map(TEAM_ABBREVIATIONS)\n",
    "                        else:\n",
    "                            df[['Player', 'Team']] = df['Player'].str.rsplit(' ', n=1, expand=True)\n",
    "                    else:  # 'stats'\n",
    "                        df[['Player', 'Team']] = df['Player'].apply(\n",
    "                            lambda s: pd.Series(\n",
    "                                re.match(r'^(.*?)\\s+\\((\\w{2,3})\\)$', s).groups()\n",
    "                                if re.match(r'^(.*?)\\s+\\((\\w{2,3})\\)$', s)\n",
    "                                else (s, None)\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                    # Add Week, Year, Position columns\n",
    "                    df['Week'] = week\n",
    "                    df['Year'] = year\n",
    "                    df['Position'] = position.upper()\n",
    "                    \n",
    "                    # Store in the appropriate dictionary\n",
    "                    if data_type == 'projections':\n",
    "                        projections_week[position] = df\n",
    "                    else:\n",
    "                        actuals_week[position] = df\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred fetching {data_type} for {position.upper()} Week {week}, {year}: {e}\")\n",
    "                    continue\n",
    "\n",
    "        # Merge the data for the current week and year\n",
    "        for position in POSITIONS:\n",
    "            proj_df = projections_week.get(position)\n",
    "            actual_df = actuals_week.get(position)\n",
    "\n",
    "            if proj_df is not None and not proj_df.empty:\n",
    "                if actual_df is not None and not actual_df.empty:\n",
    "                    merged_df = pd.merge(\n",
    "                        proj_df,\n",
    "                        actual_df,\n",
    "                        on=['Player', 'Week', 'Year'],\n",
    "                        how='left',\n",
    "                        suffixes=('_proj', '_actual')\n",
    "                    )\n",
    "                else:\n",
    "                    merged_df = proj_df\n",
    "                    print(f\"No actuals data found for {position.upper()} Week {week}, {year}. Using projections only for this week.\")\n",
    "                \n",
    "                merged_position_dfs[position] = pd.concat([merged_position_dfs[position], merged_df], ignore_index=True)\n",
    "            elif proj_df is None or proj_df.empty:\n",
    "                print(f\"No projections data for {position.upper()} Week {week}, {year}. Skipping this position for this week.\")\n",
    "\n",
    "# Save the final merged data to CSV files for each position and store position data into a full dataframe\n",
    "print(\"\\n--- Saving the final merged data to CSV files ---\")\n",
    "full_merged_df = pd.DataFrame()\n",
    "for position, df in merged_position_dfs.items():\n",
    "    if not df.empty:\n",
    "        filename = f\"{position}_merged_data.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Saved {filename}\")\n",
    "        full_merged_df = pd.concat([full_merged_df, df], ignore_index=True)\n",
    "\n",
    "# Save the full merged dataframe\n",
    "if not full_merged_df.empty:\n",
    "    full_filename = \"full_merged_data.csv\"\n",
    "    full_merged_df.to_csv(full_filename, index=False)\n",
    "    print(f\"Saved combined file: {full_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
